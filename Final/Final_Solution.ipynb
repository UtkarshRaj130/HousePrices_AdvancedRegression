{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17041,"status":"ok","timestamp":1724847817171,"user":{"displayName":"Nidhish Doshi","userId":"17660794929398760550"},"user_tz":-330},"id":"bRKUkqfEFUF9","outputId":"85e2d7d8-d2b3-4b79-ef30-5ad639e35690"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting catboost\n","  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n","Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: catboost\n","Successfully installed catboost-1.2.5\n"]}],"source":["!pip install catboost"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":975117,"status":"ok","timestamp":1724848840177,"user":{"displayName":"Nidhish Doshi","userId":"17660794929398760550"},"user_tz":-330},"id":"iOSCtEQJ8Dwf","outputId":"16240b78-8be7-4e10-a1ff-eec7668721d3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["Null Values in each column:\n"," MSZoning           4\n","LotFrontage      486\n","Alley           2721\n","Utilities          2\n","Exterior1st        1\n","Exterior2nd        1\n","MasVnrType      1766\n","MasVnrArea        23\n","BsmtQual          81\n","BsmtCond          82\n","BsmtExposure      82\n","BsmtFinType1      79\n","BsmtFinSF1         1\n","BsmtFinType2      80\n","BsmtFinSF2         1\n","BsmtUnfSF          1\n","TotalBsmtSF        1\n","Electrical         1\n","BsmtFullBath       2\n","BsmtHalfBath       2\n","KitchenQual        1\n","Functional         2\n","FireplaceQu     1420\n","GarageType       157\n","GarageYrBlt      159\n","GarageFinish     159\n","GarageCars         1\n","GarageArea         1\n","GarageQual       159\n","GarageCond       159\n","PoolQC          2909\n","Fence           2348\n","MiscFeature     2814\n","SaleType           1\n","SalePrice       1459\n","dtype: int64\n","\n","Total Null Values:  17166\n","\n","Dropping features with more than 500 null values: []\n","Data after one-hot encoding:\n","    Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n","0   1          60         65.0     8450            7            5       2003   \n","1   2          20         80.0     9600            6            8       1976   \n","2   3          60         68.0    11250            7            5       2001   \n","3   4          70         60.0     9550            7            5       1915   \n","4   5          60         84.0    14260            8            5       2000   \n","\n","   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_ConLI  SaleType_ConLw  \\\n","0          2003       196.0       706.0  ...           False           False   \n","1          1976         0.0       978.0  ...           False           False   \n","2          2002       162.0       486.0  ...           False           False   \n","3          1970         0.0       216.0  ...           False           False   \n","4          2000       350.0       655.0  ...           False           False   \n","\n","   SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_AdjLand  \\\n","0         False         False         True                  False   \n","1         False         False         True                  False   \n","2         False         False         True                  False   \n","3         False         False         True                  False   \n","4         False         False         True                  False   \n","\n","   SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n","0                 False                 False                  True   \n","1                 False                 False                  True   \n","2                 False                 False                  True   \n","3                 False                 False                 False   \n","4                 False                 False                  True   \n","\n","   SaleCondition_Partial  \n","0                  False  \n","1                  False  \n","2                  False  \n","3                  False  \n","4                  False  \n","\n","[5 rows x 247 columns]\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001112 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3395\n","[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 155\n","[LightGBM] [Info] Start training from score 181441.541952\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000641 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3175\n","[LightGBM] [Info] Number of data points in the train set: 934, number of used features: 147\n","[LightGBM] [Info] Start training from score 181121.274090\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000892 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3166\n","[LightGBM] [Info] Number of data points in the train set: 934, number of used features: 147\n","[LightGBM] [Info] Start training from score 179912.635974\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000995 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3164\n","[LightGBM] [Info] Number of data points in the train set: 934, number of used features: 142\n","[LightGBM] [Info] Start training from score 182516.069593\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000898 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3168\n","[LightGBM] [Info] Number of data points in the train set: 935, number of used features: 145\n","[LightGBM] [Info] Start training from score 182235.731551\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000844 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3163\n","[LightGBM] [Info] Number of data points in the train set: 935, number of used features: 145\n","[LightGBM] [Info] Start training from score 181421.170053\n","\n","Validation Logarithmic RMSE: 0.1457278547491009\n","Validation R² Score: 0.8861985148337437\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001046 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3662\n","[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 162\n","[LightGBM] [Info] Start training from score 180921.195890\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000815 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3380\n","[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 158\n","[LightGBM] [Info] Start training from score 180717.091610\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3392\n","[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 155\n","[LightGBM] [Info] Start training from score 180407.575342\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001229 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3383\n","[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 157\n","[LightGBM] [Info] Start training from score 180007.375000\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000890 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3406\n","[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 155\n","[LightGBM] [Info] Start training from score 182883.660103\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000809 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 3390\n","[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 157\n","[LightGBM] [Info] Start training from score 180590.277397\n","\n","Predictions saved to test_predictions.csv\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.ensemble import StackingRegressor\n","from sklearn.linear_model import Ridge\n","from xgboost import XGBRegressor\n","import lightgbm as lgb\n","from catboost import CatBoostRegressor\n","\n","# Step 1: Import train.csv and test.csv\n","train = pd.read_csv('train.csv')\n","test = pd.read_csv('test.csv')\n","\n","# Store the original test ID for reference later\n","test_ids = test.index\n","\n","# Step 2: Concatenate the train and test datasets\n","# Create a new column 'Source' to distinguish between train and test data\n","train['Source'] = 1\n","test['Source'] = 0\n","\n","# Concatenate train and test data\n","combined = pd.concat([train, test], axis=0, ignore_index=True)\n","\n","# Step 3: Check for Null Values and analyze it in combined data\n","null_values = combined.isnull().sum()\n","print(\"Null Values in each column:\\n\", null_values[null_values > 0])\n","print(\"\\nTotal Null Values: \", null_values.sum())\n","\n","# Separate numeric and categorical columns\n","numeric_cols = combined.select_dtypes(include=['number']).columns\n","categorical_cols = combined.select_dtypes(include=['object']).columns\n","\n","# Fill missing values for numeric columns with the median\n","combined[numeric_cols] = combined[numeric_cols].fillna(combined[numeric_cols].median())\n","\n","# Fill missing values for categorical columns with the mode (most frequent value)\n","for col in categorical_cols:\n","    mode_val = combined[col].mode()[0]  # Get the most frequent value\n","    combined[col].fillna(mode_val, inplace=True)\n","\n","# Drop features with more than 500 null values\n","null_values = combined.isnull().sum()\n","features_to_drop = null_values[null_values > 500].index\n","print(f\"\\nDropping features with more than 500 null values: {features_to_drop.tolist()}\")\n","combined.drop(columns=features_to_drop, inplace=True)\n","\n","# Update categorical columns after dropping features\n","categorical_cols = combined.select_dtypes(include=['object']).columns\n","\n","# Step 4: One-hot encoding for each string-based feature\n","# Apply one-hot encoding to categorical variables\n","combined = pd.get_dummies(combined, columns=categorical_cols, drop_first=True)\n","\n","print(\"Data after one-hot encoding:\\n\", combined.head())\n","\n","# Step 5: Split combined data back into train and test sets\n","train_data = combined[combined['Source'] == 1].drop('Source', axis=1)\n","test_data = combined[combined['Source'] == 0].drop('Source', axis=1)\n","\n","# Ensure the columns match exactly between train and test data\n","X = train_data.drop(columns=['SalePrice'])\n","y = train_data['SalePrice']\n","\n","# Step 6: Split the training data into train and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 7: Define base models and stacking model\n","estimators = [\n","    ('xgb', XGBRegressor(n_estimators=1000, learning_rate=0.05, max_depth=10, random_state=42)),\n","    ('lgbm', lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=31, random_state=42)),\n","    ('catboost', CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=10, random_seed=42, verbose=0))\n","]\n","\n","# Initialize the stacking model with Ridge as the final estimator\n","stacking_model = StackingRegressor(estimators=estimators, final_estimator=Ridge())\n","\n","# Train the stacking model on the training data\n","stacking_model.fit(X_train, y_train)\n","\n","# Step 8: Predict on the validation set\n","y_val_pred = stacking_model.predict(X_val)\n","\n","# Calculate the logarithm of the predictions and the actual values\n","y_val_log_pred = np.log1p(y_val_pred)\n","y_val_log_actual = np.log1p(y_val)\n","\n","# Step 9: Calculate Logarithmic RMSE and R² score\n","log_rmse = np.sqrt(mean_squared_error(y_val_log_actual, y_val_log_pred))\n","r2 = r2_score(y_val_log_actual, y_val_log_pred)\n","\n","print(f\"\\nValidation Logarithmic RMSE: {log_rmse}\")\n","print(f\"Validation R² Score: {r2}\")\n","\n","# Step 10: Predict on the test set using the entire training data\n","stacking_model.fit(X, y)  # Re-train on the entire dataset before predicting on the test set\n","y_test_pred = stacking_model.predict(test_data[X_train.columns])\n","\n","# Handle any extremely large or small predictions\n","y_test_pred = np.clip(y_test_pred, 0, np.percentile(y_test_pred, 99))\n","\n","# Step 11: Save the predictions to a CSV file\n","output = pd.DataFrame({'Id': test_ids, 'SalePrice': y_test_pred})\n","output.to_csv('test_predictions.csv', index=False)\n","\n","print(\"\\nPredictions saved to test_predictions.csv\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPgo138q2J5v1TB+JBQoYmU","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
